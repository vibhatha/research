"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[4042],{3899(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>c,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"deepseek-ocr/intro","title":"Introduction","description":"BETAResearch Work in Progress","source":"@site/docs/deepseek-ocr/intro.md","sourceDirName":"deepseek-ocr","slug":"/deepseek-ocr/intro","permalink":"/research/docs/deepseek-ocr/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/vibhatha/research/tree/main/docs/docs/deepseek-ocr/intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Full Acts Library","permalink":"/research/docs/legislative-analysis/archive"},"next":{"title":"Setup","permalink":"/research/docs/deepseek-ocr/setup"}}');var r=t(4848),i=t(8453);const o={sidebar_position:1},c="Introduction",l={},a=[{value:"Documentation",id:"documentation",level:2},{value:"Findings",id:"findings",level:3},{value:"Technology",id:"technology",level:3},{value:"Objectives",id:"objectives",level:2},{value:"Architecture",id:"architecture",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"introduction",children:"Introduction"})}),"\n",(0,r.jsx)("span",{className:"status-badge status-badge--beta",children:"BETA"}),"\n",(0,r.jsx)("span",{className:"status-text",children:"Research Work in Progress"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.strong,{children:"DeepSeek OCR"})," project evaluates the performance of DeepSeek-VL (Vision Language) models for Optical Character Recognition, particularly focusing on complex document structures and Sri Lankan legal texts."]}),"\n",(0,r.jsx)(n.h2,{id:"documentation",children:"Documentation"}),"\n",(0,r.jsx)(n.h3,{id:"findings",children:"Findings"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"./experiments",children:(0,r.jsx)(n.strong,{children:"Experiments"})})," - DeepSeek OCR vs Gemini 2.0 comparison study"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"technology",children:"Technology"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"./setup",children:(0,r.jsx)(n.strong,{children:"Setup"})})," - Installation and environment configuration"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"./usage",children:(0,r.jsx)(n.strong,{children:"Usage"})})," - How to use the OCR library"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"objectives",children:"Objectives"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Benchmark Accuracy"}),": Evaluating text extraction quality against standard OCR tools."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Structured Extraction"}),": Successfully demonstrating the ability to extract organizational charts and tabular data directly into JSON."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Optimization"}),": Re-using the loaded model for both OCR and post-processing to minimize VRAM usage."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"architecture",children:"Architecture"}),"\n",(0,r.jsxs)(n.p,{children:["The project has evolved into a reusable Python library ",(0,r.jsx)(n.code,{children:"ldf.deepseek.ocr"})," that supports:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Batch Processing"}),": Efficiently processing folders of PDF documents."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multi-Agent Workflow"}),": A sophisticated pipeline involving:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Extractor"}),": Runs the core DeepSeek-OCR model to get raw text."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Processor"}),": Structures raw text into JSON based on custom prompts/schemas."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Aggregator"}),": Stitches multi-page documents together, handling context continuation."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Finalizer"}),": Validates and saves the consolidated output."]}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453(e,n,t){t.d(n,{R:()=>o,x:()=>c});var s=t(6540);const r={},i=s.createContext(r);function o(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);